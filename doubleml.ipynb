{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "All the imports. simutils contains a set of functions I created for generating synthetic data for these experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install statsmodels\n",
    "#!pip install scikit-learn\n",
    "#!pip install numpy\n",
    "#!pip install pandas\n",
    "#!pip install matplotlib\n",
    "#!pip install scipy\n",
    "\n",
    "import simutils as sim\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor Variables of Non-Interest\n",
    "First, create some synthetic age, credit score and arbitrary hypothetically relevant personality characteristic values. Most of these variables are nuisance or confounding variables, but will partially determine both the predictor of interest and the dependent variable.\n",
    "\n",
    "Age will be normally distributed (M=35, SD=10) and range from 18 to 78. Credit scores are 700-730 on average, but tend to be lower for younger people, and are reduced by up to 40 points for the youngest, relative to the oldest. The hypothetical personality variable will reflect whatever set of intrinsic characteristics (e.g., inquisitiveness, intelligence) that are normally distributed and might drive the behaviour of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>personality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38</td>\n",
       "      <td>721</td>\n",
       "      <td>-0.444072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>631</td>\n",
       "      <td>-0.116099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42</td>\n",
       "      <td>751</td>\n",
       "      <td>-1.038549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>763</td>\n",
       "      <td>-1.086927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>572</td>\n",
       "      <td>1.264644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  credit_score  personality\n",
       "0   38           721    -0.444072\n",
       "1   24           631    -0.116099\n",
       "2   42           751    -1.038549\n",
       "3   44           763    -1.086927\n",
       "4   18           572     1.264644"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N=50000\n",
    "ages=sim.generate_ages(35, 10, N)\n",
    "credit_scores=sim.generate_credit_scores(ages)\n",
    "personality=np.random.normal(loc=0, scale=1, size=N)\n",
    "#create data frame out of factors\n",
    "Z=pd.DataFrame({\n",
    "    'age': ages,\n",
    "    'credit_score': credit_scores,\n",
    "    'personality': personality\n",
    "    })\n",
    "Z.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor of Interest\n",
    "The independent measure will be the number of recorded interactions with product information pages, obtained from cookies, since monitoring was implemented.\n",
    "\n",
    "Our goal will be to determine the causal relationship between clicking behavior and the dependent variable, personal wealth. This relationship can be quantified by computing the coefficient or weight in a regression or machine learning model that predicts wealth from clicks.\n",
    "\n",
    "Clicking behavior will be influenced by all three of the variables in Z. These influences will be non-linear, which would make a linear regression-based approach a poor choice, though the number of clicks will be a linear combination of all three influences. I will explicitly determine each confound's influence on an individual's clicking behavior, making it easier to establish the ground-truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_delta</th>\n",
       "      <th>csv_delta</th>\n",
       "      <th>personality_delta</th>\n",
       "      <th>baseline</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>49</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>46</td>\n",
       "      <td>22</td>\n",
       "      <td>43</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age_delta  csv_delta  personality_delta  baseline  total\n",
       "0         44          8                  5        22     79\n",
       "1         33         32                  8        49    122\n",
       "2         60         11                  0        47    118\n",
       "3         62         15                  0        26    103\n",
       "4         -1         46                 22        43    110"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import randint\n",
    "\n",
    "clicks=sim.generate_clicks(Z)\n",
    "clicks.columns=['age_delta', 'csv_delta', 'personality_delta']\n",
    "#external random factors are responsible for the baseline number of interactions\n",
    "clicks['baseline'] = randint.rvs(10,50, size=N)\n",
    "clicks['total'] = clicks.apply(np.sum, axis=1)\n",
    "clicks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the perspective of an all-knowing oracle, we can isolate the total number of clicks for each person that were not attributable to either age or credit score value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_clicks=pd.DataFrame(clicks['personality_delta']+clicks['baseline'])\n",
    "clean_clicks.columns=['i_total']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dependent Variable: Wealth/Value\n",
    "Now to create the dependent variable, portfolio value, we can use a similar procedure. The DV value will be caused in part by the number of clicks, as well as age and credit score and we can see whether we can tease apart these components. **Every click causes an increases a person's wealth by $500**, and this is the causal parameter we are trying to discover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_wealth</th>\n",
       "      <th>csv_wealth</th>\n",
       "      <th>click_wealth</th>\n",
       "      <th>circumstance_wealth</th>\n",
       "      <th>total_wealth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18379</td>\n",
       "      <td>54368</td>\n",
       "      <td>39495</td>\n",
       "      <td>50511</td>\n",
       "      <td>162753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15229</td>\n",
       "      <td>39603</td>\n",
       "      <td>60993</td>\n",
       "      <td>46389</td>\n",
       "      <td>162214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35530</td>\n",
       "      <td>60454</td>\n",
       "      <td>58996</td>\n",
       "      <td>49019</td>\n",
       "      <td>203999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38973</td>\n",
       "      <td>63080</td>\n",
       "      <td>51499</td>\n",
       "      <td>35098</td>\n",
       "      <td>188650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11037</td>\n",
       "      <td>32217</td>\n",
       "      <td>54991</td>\n",
       "      <td>35384</td>\n",
       "      <td>133629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age_wealth  csv_wealth  click_wealth  circumstance_wealth  total_wealth\n",
       "0       18379       54368         39495                50511        162753\n",
       "1       15229       39603         60993                46389        162214\n",
       "2       35530       60454         58996                49019        203999\n",
       "3       38973       63080         51499                35098        188650\n",
       "4       11037       32217         54991                35384        133629"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#baseline wealth increases as individuals get older until ~75, at which point it drops off\n",
    "age_wealth=Z.apply(lambda row: sim.age_worth(row[0]), axis=1)\n",
    "#baseline wealth increases for people with better credit scores, who can get better rates\n",
    "csv_wealth=Z.apply(lambda row: sim.csv_worth(row[1]), axis=1)\n",
    "#wealth increases caused by the behavior we care about (clicks), itself influenced by age and credit\n",
    "click_wealth=clicks.apply(lambda row: sim.clicks_worth(row[4]), axis=1)\n",
    "#wealth attributable to all the other random chance factors\n",
    "circumstance_wealth=clicks.apply(lambda row: sim.circumstance_worth(), axis=1)\n",
    "wealth=pd.concat([age_wealth, csv_wealth, click_wealth, circumstance_wealth], axis=1)\n",
    "wealth.columns=['age_wealth', 'csv_wealth', 'click_wealth', 'circumstance_wealth']\n",
    "wealth[\"total_wealth\"]=wealth.apply(np.sum, axis=1)\n",
    "wealth.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like for clicks, I want the oracle measure of the wealth attributable to those clicks that were not driven by age and credit score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_wealth=clean_clicks.apply(lambda row: sim.clicks_worth(row[0]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Multiple Regression\n",
    "So the goal is to use the customer's interaction data (\"clicks\") to explain the value of their portfolio (\"total wealth\"). In this scenario, we have reason to believe that age and credit score affect both the number of interactions and the customer's total wealth and need to remove these confounding effects. Before we do so, let's run a naive multiple regression, paying attention to the coefficient for the clicks variable, to see the impact of the confounding variables on our parameter estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.906\n",
      "Model:                            OLS   Adj. R-squared:                  0.906\n",
      "Method:                 Least Squares   F-statistic:                 1.606e+05\n",
      "Date:                Mon, 06 Nov 2023   Prob (F-statistic):               0.00\n",
      "Time:                        14:57:19   Log-Likelihood:            -5.3157e+05\n",
      "No. Observations:               50000   AIC:                         1.063e+06\n",
      "Df Residuals:                   49996   BIC:                         1.063e+06\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept   1.022e+05   2785.385     36.708      0.000    9.68e+04    1.08e+05\n",
      "clicks       650.8572      2.203    295.486      0.000     646.540     655.174\n",
      "age         3738.5858     41.653     89.756      0.000    3656.946    3820.226\n",
      "csv         -188.8078      6.024    -31.344      0.000    -200.615    -177.001\n",
      "==============================================================================\n",
      "Omnibus:                    31786.190   Durbin-Watson:                   2.006\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           948223.911\n",
      "Skew:                           2.590   Prob(JB):                         0.00\n",
      "Kurtosis:                      23.696   Cond. No.                     4.43e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.43e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y=wealth[\"total_wealth\"]\n",
    "x=clicks[\"total\"]\n",
    "basedf=pd.DataFrame({'y': y, 'clicks': x})\n",
    "basedf[\"age\"]=Z[\"age\"]\n",
    "basedf[\"csv\"]=Z[\"credit_score\"]\n",
    "\n",
    "naive_model = smf.ols(formula='y ~ 1 + clicks + age + csv', data = basedf).fit()\n",
    "print(naive_model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above model summary, the coefficient estimate for clicks is quite biased: we know the true value to be 500, so the model is greatly overestimating the impact of clicking. There's also an indicator of potential multicollinearity, which is not at all surprising, since age and csv drive the number of clicks.\n",
    "\n",
    "## Double Machine Learning\n",
    "Now let's use double machine learning to try to remove the confounding effects of age and credit score. This is done by using the confounders to predict the variables we care about (clicks and wealth), and calculating the residuals. The residualized values are the components of the variables of interest that couldn't be adequately predicted by the confounders, and are orthogonal with respect to the confounding variables.\n",
    "\n",
    "The particular ML algorithm used isn't critical, as long as it is appropriate for your variables. Here, I am predicting continuous integer values, and had never before had an opportunity to try out a boosted decision tree algorithm. For categorical data, an SVM or even neural network might be appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Y_hat   R-squared:                       0.712\n",
      "Model:                            OLS   Adj. R-squared:                  0.712\n",
      "Method:                 Least Squares   F-statistic:                 1.233e+05\n",
      "Date:                Mon, 06 Nov 2023   Prob (F-statistic):               0.00\n",
      "Time:                        14:57:42   Log-Likelihood:            -4.9725e+05\n",
      "No. Observations:               50000   AIC:                         9.945e+05\n",
      "Df Residuals:                   49998   BIC:                         9.945e+05\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.5582     22.558      0.025      0.980     -43.656      44.773\n",
      "X_hat        500.6779      1.426    351.195      0.000     497.884     503.472\n",
      "==============================================================================\n",
      "Omnibus:                        2.909   Durbin-Watson:                   2.012\n",
      "Prob(Omnibus):                  0.234   Jarque-Bera (JB):                2.902\n",
      "Skew:                          -0.019   Prob(JB):                        0.234\n",
      "Kurtosis:                       3.005   Cond. No.                         15.8\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "M_clicks=GradientBoostingRegressor()\n",
    "M_wealth=GradientBoostingRegressor()\n",
    "\n",
    "#use cross-validation values to obtain residuals\n",
    "residualized_y = y-cross_val_predict(M_wealth, Z[[\"age\", \"credit_score\"]], y, cv=3)\n",
    "residualized_x = x-cross_val_predict(M_clicks, Z[[\"age\", \"credit_score\"]], x, cv=3)\n",
    "df=pd.DataFrame()\n",
    "df[\"Y_hat\"]=residualized_y\n",
    "df[\"X_hat\"]=residualized_x\n",
    "df[\"clean_X\"]=clean_clicks\n",
    "df[\"dirty_Y\"]=wealth[\"click_wealth\"]\n",
    "df[\"clean_Y\"]=clean_wealth\n",
    "\n",
    "#fit the residualized data and check out the model prediction\n",
    "DML_model = smf.ols(formula='Y_hat ~ 1 + X_hat', data = df).fit()\n",
    "print(DML_model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oracle Models\n",
    "The double-ML model using the orthogonalized values are much closer to the true parameter value.\n",
    "\n",
    "From the perspective of an all-knowing oracle, we can compare the double-ML results against models using the ground-truth oracle data. In my first attempt, I modeled wealth values that were computed only using the total number of clicks (which itself was influenced by age and credit score), which I then realized doesn't quite capture what double-ML was supposed to have done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                dirty_Y   R-squared:                       0.484\n",
      "Model:                            OLS   Adj. R-squared:                  0.484\n",
      "Method:                 Least Squares   F-statistic:                 4.684e+04\n",
      "Date:                Mon, 06 Nov 2023   Prob (F-statistic):               0.00\n",
      "Time:                        14:57:42   Log-Likelihood:            -5.1883e+05\n",
      "No. Observations:               50000   AIC:                         1.038e+06\n",
      "Df Residuals:                   49998   BIC:                         1.038e+06\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept   3.227e+04     96.617    333.962      0.000    3.21e+04    3.25e+04\n",
      "clean_X      499.1643      2.306    216.426      0.000     494.644     503.685\n",
      "==============================================================================\n",
      "Omnibus:                     1095.812   Durbin-Watson:                   2.006\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              787.354\n",
      "Skew:                           0.206   Prob(JB):                    1.07e-171\n",
      "Kurtosis:                       2.543   Cond. No.                         117.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#fit the number of clicks unrelated to age/credit score to the wealth attributable to clicks alone\n",
    "Oracle_model_1 = smf.ols(formula='dirty_Y ~ 1 + clean_X', data = df).fit()\n",
    "print(Oracle_model_1.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I followed up by repeating the model, using the click behavior not attributable to age and credit score to generate the wealth attributable to the clicking behavior that is also not attributable to age and credit score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                clean_Y   R-squared:                       1.000\n",
      "Model:                            OLS   Adj. R-squared:                  1.000\n",
      "Method:                 Least Squares   F-statistic:                 8.542e+10\n",
      "Date:                Mon, 06 Nov 2023   Prob (F-statistic):               0.00\n",
      "Time:                        14:57:42   Log-Likelihood:            -1.5850e+05\n",
      "No. Observations:               50000   AIC:                         3.170e+05\n",
      "Df Residuals:                   49998   BIC:                         3.170e+05\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -0.5121      0.072     -7.145      0.000      -0.653      -0.372\n",
      "clean_X      500.0008      0.002   2.92e+05      0.000     499.997     500.004\n",
      "==============================================================================\n",
      "Omnibus:                    46942.483   Durbin-Watson:                   1.999\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3032.213\n",
      "Skew:                          -0.009   Prob(JB):                         0.00\n",
      "Kurtosis:                       1.794   Cond. No.                         117.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#fit the number of clicks unrelated to age/credit score to the wealth attributable to clicks alone\n",
    "Oracle_model_2 = smf.ols(formula='clean_Y ~ 1 + clean_X', data = df).fit()\n",
    "print(Oracle_model_2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Orthogonalized Scores to Oracle Values\n",
    "A final question to consider is whether the orthogonalized scores are equivalent to \"clean\" data; that is, whether they map to the ground-truth oracle data without the influence of the nuisance variables. Consider that we have access to the components of each person's click behaviour that are independent of age and credit score. We can quantify the correspondence of these values with the residualized scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The residualized values are correlated at 95% with the true values and 71% with the dirty values\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "res=stats.spearmanr(residualized_x, clean_clicks)\n",
    "bad=stats.spearmanr(residualized_x, clicks[\"total\"])\n",
    "print(f\"The residualized values are correlated at {int(res.statistic*100)}% with the true values and {int(bad.statistic *100)}% with the dirty values\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
